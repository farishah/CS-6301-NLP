{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Farishah Nahrin\n",
        "\n",
        "CS 6301.M02 - Special Topics in Computer Science\n",
        "\n",
        "NLP"
      ],
      "metadata": {
        "id": "pqNJkmhAfhQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Portfolio Assignment: Wordnet\n",
        "\n",
        "Code was inspired by Dr. Karen Mazidi's Github directory: https://github.com/kjmazidi/NLP/tree/master/Part_2-Words/Chapter_07_WordNet"
      ],
      "metadata": {
        "id": "UxUCKQQ5fpoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is wordnet? \n",
        "\n",
        "WordNet is a \"lexical database of nouns, verbs, adjectives and adverbs that provides short definitions called *glosses*, and use examples.\" WordNet started as a project at Princeton University, organized by George Miller. The primary premise of the project was \"to support theories of human semantic memory, which suggested that people organize concepts mentally in some kind of hierarchy.\" In NLTK, WordNet is just another NLTK corpus reader, that is created for natural language processing and can be used for translating language automatically, text similarity, to disambiguate words, as a thesaurus. In WordNet, you can use \"sysnet\" to look up words, and the Sysnet function also has an optional POS argument which lets you constrain the part of speech of a word. Each sysnet contains one or more lemmas, which represent a specific sense of a word. With Sysnet, you can display a set of synonyms of a word as well.\n",
        "\n",
        "Source: https://www.nltk.org/howto/wordnet.html, and Chapter 7 - Exploring NLP with Python by Dr. Karen Mazidi"
      ],
      "metadata": {
        "id": "vvSmQ8lRfvZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import NLTK libraries for this Project"
      ],
      "metadata": {
        "id": "SLhUWkp_mD_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrZZE9WpmPw5",
        "outputId": "e1368694-4cd2-4406-f588-200bff8ac19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select a Noun\n",
        "\n",
        "Output all synsets. Select one synset from the list of synsets. Extract its definition, usage examples, and lemmas. From your selected synset, traverse up the WordNet hierarchy as far as you can, outputting the synsets as you go. "
      ],
      "metadata": {
        "id": "erOl0ggomaOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noun_details(noun:str = None):\n",
        "    if noun is None or type(noun)!=str:\n",
        "        print(\"The noun must be of 'str' type!\")\n",
        "    #Print synsets of noun\n",
        "    print(\"\\nSynsets are:\")\n",
        "    print(*wn.synsets(noun), sep='\\n') \n",
        "    #Select first synset of noun\n",
        "    #I chose Gladden\n",
        "    noun_synsets = wn.synsets(noun)\n",
        "    #Selected synset\n",
        "    noun_synset = noun_synsets[-1]\n",
        "    print(f\"Selected Synset is: {noun_synset.name()}\")\n",
        "    #Print synset defination\n",
        "    print(f'\\n\"{noun_synset.name()}\" is {noun_synset.definition()}')\n",
        "    #Print synset defination\n",
        "    usages = []\n",
        "    for synset in noun_synsets:\n",
        "        if synset.examples() != []:\n",
        "            usages.extend(synset.examples())\n",
        "    print(f'\\nThe usage examples are :',*usages,sep='\\n')\n",
        "    #Print lemmas of synset\n",
        "    print(\"\\nLemmas are:\")\n",
        "    print(*noun_synset.lemma_names(), sep='\\n')\n",
        "    #Print synset heirarchy in wordNet\n",
        "    print(\"\\nThe hypernyms are:\")\n",
        "    print(*noun_synset.hypernym_paths()[0][::-1], sep='\\n')\n",
        "    #Print synset hyponyms\n",
        "    print(f\"\\nThe hyponyms of {noun} are:\")\n",
        "    print(*noun_synset.hyponyms(), sep='\\n')\n",
        "    ### print meronyms\n",
        "    print(f\"\\nThe meronyms of {noun} are:\")\n",
        "    print('\\n'.join(noun_synset.part_meronyms()) or '[]')\n",
        "    ### print holonyms\n",
        "    print(f\"\\nThe holonyms of {noun} are:\")\n",
        "    print('\\n'.join(noun_synset.part_holonyms()) or '[]')\n",
        "    ### print antonyms\n",
        "    print(f\"\\nThe antonym of {noun} is:\")\n",
        "    ant = noun_synset.lemmas()[0].antonyms()\n",
        "    print(ant[0] if ant else '[]')"
      ],
      "metadata": {
        "id": "etYK43VLSNQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noun_details('joy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WNyDS_YSXK5",
        "outputId": "372ea2c4-6f8d-46bf-93b2-9dc7891e6fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Synsets are:\n",
            "Synset('joy.n.01')\n",
            "Synset('joy.n.02')\n",
            "Synset('rejoice.v.01')\n",
            "Synset('gladden.v.01')\n",
            "Selected Synset is: gladden.v.01\n",
            "\n",
            "\"gladden.v.01\" is make glad or happy\n",
            "\n",
            "The usage examples are :\n",
            "a joy to behold\n",
            "the pleasure of his company\n",
            "the new car is a delight\n",
            "\n",
            "Lemmas are:\n",
            "gladden\n",
            "joy\n",
            "\n",
            "The hypernyms are:\n",
            "Synset('gladden.v.01')\n",
            "\n",
            "The hyponyms of joy are:\n",
            "Synset('overjoy.v.01')\n",
            "\n",
            "The meronyms of joy are:\n",
            "[]\n",
            "\n",
            "The holonyms of joy are:\n",
            "[]\n",
            "\n",
            "The antonym of joy is:\n",
            "Lemma('sadden.v.01.sadden')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet organizes nouns into hierarchies of concepts, with each concept represented by a synset. A synset is a set of words that are interchangeable in some context, and each synset is associated with a unique identifier. Each sysnet contains lemmas, which are sets of words with synonyns. Within each synset, WordNet captures the relationships between words using various semantic relations. For example, a hypernym is a more general word that encompasses the meaning of a specific word (e.g., \"emotion\" is a hypernym of \"joy\"), while a hyponym is a more specific word that is encompassed by a more general word (e.g., \"emotion\" is a hyponym of \"feeling\"). Through this, we are able to observe the relationships between the words and nouns, to understand the language and context. This is especially helpful for natural language processing, which includes sentiment or text analyses."
      ],
      "metadata": {
        "id": "TQbPkRRTS_LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select a Verb\n",
        "\n",
        "Output all synsets.Select one synset from the list of synsets. Extract its definition, usage examples, and lemmas. From your selected synset, traverse up the WordNet hierarchy as far as you can, outputting the synsets as you go"
      ],
      "metadata": {
        "id": "g4ZYNa7oTHJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chosing synsets and passing v for verb\n",
        "verb_synsets = wn.synsets('work')\n",
        "#Selected Synset:\n",
        "verb_synset = verb_synsets[3]\n",
        "print(f\"Selected Synset is: {verb_synset.name()}\")\n",
        "#Printing definations\n",
        "verb_synset.definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "WHXBzr3cS80-",
        "outputId": "a3becb17-636c-46a8-fa85-116f2da5cde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Synset is: study.n.02\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'applying the mind to learning and understanding a subject (especially by reading)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing usage examples\n",
        "verb_synset.examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMTFUNqWTQk_",
        "outputId": "7e13a22d-5fbd-4d55-c0cc-46e03c33ebec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mastering a second language requires a lot of work',\n",
              " 'no schools offer graduate study in interior design']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing lemmas\n",
        "verb_synset.lemma_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCy_4eWITRm5",
        "outputId": "a20cc312-ea82-4a95-cab3-9571e61256c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['study', 'work']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Traversing\n",
        "verb_synset.hypernym_paths()[0][::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3nJ0HugTS-X",
        "outputId": "1223b281-1fa1-4b46-ce6d-733a87b86a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('study.n.02'),\n",
              " Synset('learning.n.01'),\n",
              " Synset('basic_cognitive_process.n.01'),\n",
              " Synset('process.n.02'),\n",
              " Synset('cognition.n.01'),\n",
              " Synset('psychological_feature.n.01'),\n",
              " Synset('abstraction.n.06'),\n",
              " Synset('entity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet organizes verbs into hierarchies based on their semantic relationships. Each synset represents a concept that encompasses a set of verbs that share similar meanings. The verbs within a synset are related by their senses, which represent different shades of meaning that the verb can take on. This is essentially organized similarly to nouns, where each sysnet, contains lemmas, that have verbs that express the same feeling and meaning. The grouping of sysnets and verbs are done based on their concept."
      ],
      "metadata": {
        "id": "3FxpcLgWTex6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using  morphy to find different words of the noun\n",
        "for word in verb_synset.lemma_names():\n",
        "    print(wn.morphy(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpbWIg1ETfjC",
        "outputId": "c1ba79b2-784a-4982-ffbc-b50c45cb1433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "study\n",
            "work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wu Palmer Similiarty Metric and Lesk Algorithm"
      ],
      "metadata": {
        "id": "HaVGimitTkt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select two words\n",
        "elaborate = wn.synsets('elaborate')[0]\n",
        "explain = wn.synsets('explain')[0]\n",
        "#Finding wu palmer similarity \n",
        "wn.wup_similarity(elaborate,explain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOidej8vTnGu",
        "outputId": "2774fd43-788b-4a4c-9b5c-3849d910b0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "#Since Lesk is used with contectual sentances, create a sentance\n",
        "context_sentence = \"I went to the teacher get some details about the topic\".split()\n",
        "print(lesk(context_sentence, 'elaborate'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YBPJvmuTppY",
        "outputId": "df2a37d9-21c7-4c2e-d65e-a81592944d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('elaborate.v.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both algorithms can be used to disambiguate the sense of a word in a given context, but they use different approaches to calculate the relatedness between synsets. Lesk tends to work better in cases where the context contains more specialized terms, while Wu-Palmer is better suited for cases where the context contains more general terms."
      ],
      "metadata": {
        "id": "XHTpO14mTtF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "import nltk\n",
        "nltk.download('sentiwordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ifi2VETvVi",
        "outputId": "02edf087-5c19-433a-bd26-05366c6e1a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentiWordNet"
      ],
      "metadata": {
        "id": "lUhkKsFrTzY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "#Creating synsets for loathe\n",
        "senti_synsets = list(swn.senti_synsets('loathe'))\n",
        "#Printing score of all senti_synsets\n",
        "for synset in senti_synsets:\n",
        "    print(synset.synset.name(), synset.pos_score(), synset.neg_score(), synset.obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCDds55KT0nu",
        "outputId": "aad646b5-1eb5-4aac-f3de-be6f8b4b0121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abhor.v.01 0.0 0.25 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#Creating sentence with the word, loathe\n",
        "sentence = \"I loathe the taste of carrots.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "#Outputting polarity for each word in sentence\n",
        "for token in tokens:\n",
        "    senti_synsets = list(swn.senti_synsets(token))\n",
        "    if len(senti_synsets) > 0:\n",
        "        print(token, senti_synsets[0].pos_score(), senti_synsets[0].neg_score(), senti_synsets[0].obj_score())\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46lzXrfUT4li",
        "outputId": "800c6620-1967-4993-9db5-a7d86d931721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I 0.0 0.0 1.0\n",
            "loathe 0.0 0.25 0.75\n",
            "taste 0.0 0.0 1.0\n",
            "carrots 0.0 0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "\n",
        "- The word \"loathe\" a negative polarity, which matches our intuition as it is a highly negative word.\n",
        "- The other words in the sentence are neutral\n",
        "- Knowing the polarity scores of words can be very useful in NLP applications such as sentiment analysis, where the overall sentiment of a piece of text is determined by aggregating the polarity scores of individual words. This can be helpful in understanding the sentiment of customer reviews, social media posts, and other text data. However, it is important to note that the accuracy of sentiment analysis depends on the quality of the sentiment lexicon used, and the context in which the words are used. Sometimes with underlying satire, sarcasm, and bias, determining the polarity can be used to label and track the emotion that a body of text evokes. This can be used to analyze customer reviews, for examples, to determine and filter which reviews were positive, netural, or negative.\n",
        "- Thus, SentiWordNet is the most widely used lexicon to perform tasks related to opinion mining. In SentiWordNet, each synset of WordNet is being assigned the three sentiment numerical scores; positive, negative and objective that are calculated using by a set of classifiers."
      ],
      "metadata": {
        "id": "J3dzl-lKT7nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collocations"
      ],
      "metadata": {
        "id": "i3-w7si2T-Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.book import text4\n",
        "#Print collocations for text4\n",
        "text4.collocation_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eho16y_UHkp",
        "outputId": "9bb64e07-4b05-49dd-9bbc-99bc2c0c771f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('United', 'States'),\n",
              " ('fellow', 'citizens'),\n",
              " ('years', 'ago'),\n",
              " ('four', 'years'),\n",
              " ('Federal', 'Government'),\n",
              " ('General', 'Government'),\n",
              " ('American', 'people'),\n",
              " ('Vice', 'President'),\n",
              " ('God', 'bless'),\n",
              " ('Chief', 'Justice'),\n",
              " ('one', 'another'),\n",
              " ('fellow', 'Americans'),\n",
              " ('Old', 'World'),\n",
              " ('Almighty', 'God'),\n",
              " ('Fellow', 'citizens'),\n",
              " ('Chief', 'Magistrate'),\n",
              " ('every', 'citizen'),\n",
              " ('Indian', 'tribes'),\n",
              " ('public', 'debt'),\n",
              " ('foreign', 'nations')]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutual Information\n",
        "MI = log( p(x,y) / \\[p(x)*p(y) \\])"
      ],
      "metadata": {
        "id": "B34tnBbXUKWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is used from https://github.com/kjmazidi/NLP/blob/master/Part_2-Words/Chapter_07_WordNet/7.5_collocations.ipynb\n",
        "import math\n",
        "import random\n",
        "random.seed(123)\n",
        "\n",
        "#Selecting one collocation\n",
        "choice = random.choice(text4.collocation_list())\n",
        "print('Choice = '+' '.join(choice))\n",
        "text = ' '.join(text4.tokens)\n",
        "vocab = len(set(text4))\n",
        "xy = text.count(f'{choice[0]} {choice[1]}')/vocab\n",
        "print(f'p({choice[0]} {choice[1]}) =',xy )\n",
        "x = text.count(choice[0])/vocab\n",
        "print(f\"p({choice[0]}) = \", x)\n",
        "y = text.count(f'{choice[1]}')/vocab\n",
        "print(f'p({choice[1]}) = ', y)\n",
        "pmi = math.log2(xy / (x * y))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHAYhAqAULk9",
        "outputId": "42986b56-ead5-4ea7-9118-83e6fec76fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choice = fellow citizens\n",
            "p(fellow citizens) = 0.006084788029925187\n",
            "p(fellow) =  0.013665835411471322\n",
            "p(citizens) =  0.026932668329177057\n",
            "pmi =  4.0472042737811735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "The mutual Information formula is a measure of the association between two words. The higher the MI score, the stronger the association between the two words. In this case, the MI score for **\"fellow citizens\"** is **4.04**, which is a relatively high score. This indicates that the words \"fellow\" and \"citizens\" are strongly associated with each other in the text, which makes sense given the political context of the Inaugural corpus. Thus, Collocations are two or more words that tend to appear frequently together, for example – United States. Collocation traces the appearance of words that commonly appear next to each other in a text or series of text in order to analyze the words' importance.\n",
        "\n",
        "This measure of association can be useful in various NLP tasks, such as identifying important collocations, detecting sentiment expressions, and classifying documents based on topic. However, it is important to note that MI can be affected by the frequency of the individual words, which may lead to skewed results in some cases. Therefore, it is important to use MI in conjunction with other measures of association and to carefully interpret the results."
      ],
      "metadata": {
        "id": "HhuXeGm7UVhY"
      }
    }
  ]
}